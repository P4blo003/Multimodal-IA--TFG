# -----------------------------------------------------------------------------
# MULTIMODAL-IA--TFG - Proyecto TFG
# (c) 2025 Pablo González García
# Universidad de Oviedo, Escuela Politécncia de Ingeniería de Gijón
# Archivo: config/app.config.yaml
# Autor: Pablo González García
# Descripción:
# Archivo de configuración principal del asistente inteligente.
# Contiene parámetros relacionados con el sistema de logging,
# la conexión a bases de datos, y otros ajustes generales del sistema.
# -----------------------------------------------------------------------------


# ---- CONFIGURACIÓN ---- #
# -- Configuración del sistema -- #
system:
  logsDirectory: 'logs'       # Directorio de logs

# -- Configuración del logger de la aplicación -- #
logger:
  level: INFO                 # Nivel de log: DEBIG, INFO, WARNING, ERROR, CRITICAL
  format: '%(asctime)s - %(name)s - %(levelname)s - %(message)s'    # Formato del mensaje del log.
  datefmt: '%d-%m-%Y %H:%M:%S'    # Formato de la fecha.
  maxBytes: 10485760          # 10 MB.
  backupCount: 5              # Número de archivos de log de respaldo.

# -- Configuración de ollama -- #
ollama:
  exe: 'bin/ollama/bin/ollama'  # Ruta del binario.
  host: '127.0.0.1'             # Host del servicio ollama.
  port: 9000                    # Puerto del servicio ollama.
  silent: False                 # Si se debe mostrar los mensajes del propio servicio de ollama.
  startupWaitSeconds: 5         # Tiempo de espera para el inicio del servicio (5 segundos).
  logFile: 'ollama.serve.log'   # Nombre del fichero de logs de ollama.

# -- Configuración del modelo -- #
model:
  name: 'deepseek-r1:14b'         # Nombre del modelo a utilizar.
  temperature: 0.0                # Parámetro que controla la aleatoriedad de las respuestas.

# -- Configuración del chat -- #
chat:
  exitCommands: ['EXIT', 'QUIT']  # Comandos de salida del chat.
  maxHistorySize: 20              # Máximo tamaño del historial del chat.
  promptDir: 'config'             # Nombre del directorio del prompt de jinja2.
  promptFile: 'prompt.j2'         # Nombre del fichero del prompt de jinja2.

# -- Configuración del RAG -- #
rag:
  backend: 'HAYSTACK'                   # El backend empleado. Puede ser HAYSTACK | LANGCHAIN
  splitLength: 500                      # Tamaño del chunk en tokens/palabras.
  splitOverlap: 50                      # Overlap para mantener contexto entre chunks.
  topK: 10                              # El número de chunks más relevantes que se recuperan.
  docDirectory: 'data/raw'              # Directorio de documentos.
  persistDirectory: 'data/persistence'  # Directorio de persistencia de embeddings.
  embeddingDim: 384                     # Tamaño del embedding.
  embeddingModel: 'sentence-transformers/all-MiniLM-L6-v2'  # Modelo de embedding.
  embeddingModelsFile: 'data/cache/embedding.models.json'   # Fichero que registra la ubicación de los modelos de embedding.
  embeddingModelDirectory: 'resources/models'               # Directorio de almacenamiento de modelos.

prompt:
  templateFile: 'config/prompt.template.txt'                # Fichero con el template del prompt.
  variables: ['context', 'history', 'user_input']           # Variables que espera el prompt.