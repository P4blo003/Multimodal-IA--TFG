# -----------------------------------------------------------------------------
# MULTIMODAL-IA--TFG - Proyecto TFG
# (c) 2025 Pablo González García
# Universidad de Oviedo, Escuela Politécncia de Ingeniería de Gijón
# Archivo: config/settings.yaml
# Autor: Pablo González García
# Descripción:
# Archivo de configuración principal del asistente inteligente.
# Contiene parámetros relacionados con el sistema de logging,
# la conexión a bases de datos, y otros ajustes generales del sistema.
# -----------------------------------------------------------------------------

# ---- Parámetros ---- #

# -- Configuración del sistema -- #
system:
  logsDirectory: 'logs'   # Ruta del directorio de logs.

# -- Configuración de logging -- #
logger:
  level: INFO             # Nivel de log: DEBIG, INFO, WARNING, ERROR, CRITICAL
  format: '%(asctime)s - %(name)s - %(levelname)s - %(message)s'    # Formato del mensaje del log.
  datefmt: '%d-%m-%Y %H:%M:%S'    # Formato de la fecha.
  maxBytes: 10485760         # 10 MB.
  backupCount: 5             # Número de archivos de log de respaldo.

# -- Configuración del servicio Ollama -- #
ollama:
  executablePath: 'bin/ollama/ollama'      # Nombre del binario.
  host: '127.0.0.1'             # Host del servicio ollama.
  port: 11434                   # Puerto del servicio ollama.
  silent: False                 # Si se debe mostrar los mensajes del propio servicio de ollama.
  startupWaitSeconds: 5         # Tiempo de espera para el inicio del servicio (5 segundos).
  logFile: 'ollama.serve.log'   # Nombre del fichero de logs de ollama.
  historyMaxSize: 10            # Tamaño máximo del historial de chat.

# -- Configuración del modelo -- #
model:
  name: 'deepseek-r1:8b'      # Nombre del modelo a utilizar.
  temperature: 0.2            # Parámetro que controla la aleatoriedad de las respuestas.
  maxTokens: 1024             # Número máximo de tokens a generar.

# -- Configuración del chat -- #
chat:
  type: basic       # Tipo del chat.
  exitCommands: ['EXIT', 'QUIT', 'SALIR'] # Comandos para salir del chat.

# -- Configuración del rag -- #
rag:
  backend: 'haystack'           # Backend empleado.
  docDirectory: 'data/raw'      # Directorio de los documentos.
  validExtensions: ['.pdf', '.docx', '.txt', '.csv']  # Extensiones disponibles.
  embeddingModel: 'sentence-transformers/all-MiniLM-L6-v2'  # Modelo de embedding.
  modelDirectory: 'resources/models'                       # Ruta de almacenamiento del modelo.
  logFile: 'rag.backend.log'    # Log del backend rag.